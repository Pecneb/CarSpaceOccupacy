# CarSpaceOccupacy
IACV Project implementation, which encapsulates car space occupacy analysis with image processing techniques.

### **Project Description: Car Motion and Space Occupancy Analysis in the Dark**

#### **Overview**
This project focuses on developing a computer vision system that analyzes a video of a moving vehicle taken by a fixed camera. The primary goal is to determine the **space occupied by the vehicle** in each frame while accounting for different motion conditions, including forward translation and steering at constant curvature. The system utilizes **camera calibration data** and a **simplified vehicle model** to estimate the vehicleâ€™s 3D position on the road.

#### **Key Components**
1. **Camera Calibration:** The intrinsic parameters of the camera (K-matrix) are provided and used for geometric calculations.
2. **Vehicle Model:** A simplified model of the car includes:
   - Car width and length.
   - Distance between the rear lights.
   - Height of rear lights from the ground.
   - Distance of the rear lights from the back of the car.

#### **Assumptions**
- The moving car has a **vertical symmetry plane**.
- Two **symmetric rear lights** are visible.
- The camera observes the **back of the vehicle**.
- The road is **locally planar**.
- Between consecutive frames, the car either:
  - Translates **forwards**.
  - **Steers** with a constant curvature.

#### **System Operation**
##### **Offline Steps**
1. **Camera Calibration** to retrieve intrinsic parameters.
2. **Vehicle Model Extraction**, including dimensions and light placements.

##### **Online Steps (Per Frame Analysis)**
1. **Feature Extraction:** Identify the two symmetric rear lights (or distinct features on them).
2. **Geometric Analysis:** Determine the **3D position** of the light segment and its containing plane (Ï€).
3. **Space Occupancy Estimation:** Using the car model and computed positions, estimate the **occupied space** on the road.

#### **Geometric Principles Used**
1. **Forward Translation:**
   - If the car is moving straight, the **first and second light segments** form a **rectangle**.
   - The system finds **vanishing points** (Vx, Vy) and the **vanishing line (l)**.
   - 3D localization of the light segments is achieved using geometric constraints (e.g., **theorem of cosines**).

2. **Steering with Constant Curvature:**
   - The light segment rotates about a **center of rotation (C)**.
   - The method estimates **vanishing points** and **perpendicular constraints** to determine motion curvature.

#### **Challenges & Solutions**
1. **Poor Perspective (Parallel Viewing Rays)**
   - The method requires **sufficient perspective effects** to work.
   - If perspective is weak, additional **non-coplanar symmetric elements** are used.
   - The system estimates the carâ€™s **pose** using an **iterative refinement** approach.

2. **Car Localization Methods**
   - **Standard Homography-Based Localization:** Uses **license plate corners and light features**.
   - **Nighttime Localization from Image Pairs:** Uses **rear lights** to estimate motion.
   - **Localization with Out-of-Plane Features:** When poor perspective makes angle estimation unreliable, the **difference in symmetric elements on separate planes** is used.

3. **Iterative Refinement for Pose Estimation**
   - **Refines estimates** of direction and position.
   - Updates **vanishing points** and **horizontal vanishing lines**.
   - Uses **camera calibration matrix** to improve estimates.

### **Conclusion**
The system provides an efficient **3D reconstruction of vehicle motion** based on **video analysis**, ensuring accurate **space occupancy estimation** in **low-light conditions**. This has potential applications in **traffic monitoring, autonomous vehicle navigation, and night-time vehicle tracking**.


Since we are implementing the **space occupancy analysis system in Python**, it's best to follow a **modular, scalable project structure** that allows clean separation between components like camera calibration, feature extraction, geometric computations, and visualization.

Directory structure guide:

```
space_occupancy/
â”‚
â”œâ”€â”€ data/                         # All raw video inputs, calibration data, and sample frames
â”‚   â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ calibration/
â”‚   â””â”€â”€ sample_frames/
â”‚
â”œâ”€â”€ configs/                      # Configuration files (e.g., camera matrix, car model)
â”‚   â”œâ”€â”€ camera_intrinsics.yaml
â”‚   â””â”€â”€ car_model.yaml
â”‚
â”œâ”€â”€ src/                          # All source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Entry point
â”‚   â”œâ”€â”€ camera/                   # Camera calibration & projection logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ calibration.py
â”‚   â”‚   â””â”€â”€ projection.py
â”‚   â”‚
â”‚   â”œâ”€â”€ detection/                # Feature and light detection logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ light_detector.py
â”‚   â”‚   â””â”€â”€ feature_tracking.py
â”‚   â”‚
â”‚   â”œâ”€â”€ geometry/                 # 3D geometry, vanishing points, pose estimation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ space_occupancy.py
â”‚   â”‚   â”œâ”€â”€ plane_estimation.py
â”‚   â”‚   â””â”€â”€ vanishing_points.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Helper functions (I/O, drawing, math)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ io_utils.py
â”‚   â”‚   â”œâ”€â”€ drawing.py
â”‚   â”‚   â””â”€â”€ math_utils.py
â”‚   â”‚
â”‚   â””â”€â”€ visualization/           # Plotting, annotated videos, image output
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ viewer.py
â”‚       â””â”€â”€ video_writer.py
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for testing and visualization
â”‚   â””â”€â”€ debug_pose_estimation.ipynb
â”‚
â”œâ”€â”€ tests/                       # Unit and integration tests
â”‚   â”œâ”€â”€ test_geometry.py
â”‚   â””â”€â”€ test_light_detection.py
â”‚
â”œâ”€â”€ results/                     # Outputs: 3D reconstructions, videos, logs
â”‚   â”œâ”€â”€ plots/
â”‚   â””â”€â”€ annotated_videos/
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

### ðŸ“Œ Suggestions for Implementation
- Use **OpenCV** (`cv2`) for image I/O and basic feature detection.
- Use **NumPy** for matrix math and 3D operations.
- Consider **SciPy** or **OpenCV's solvePnP** for pose estimation.
- Store camera intrinsics and car model parameters in `.yaml` or `.json` files under `configs/`.
- Add **logging** and debugging support (e.g., timestamps, feature match quality).

Would you like me to generate a `requirements.txt` and a sample config file (like `camera_intrinsics.yaml`) to start from?